{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x119f016d8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "#output display setting\n",
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n",
      "0.3.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "#有继承的类需要把父类写在括号里\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "#规定操作，第三行要写父类的构造器，格式为super(子类，self).__init__（）括号内可\n",
    "#能有父亲类的构造参数。\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "#in_channels=1因为输入的图片为灰阶图片，此超参数由数据影响\n",
    "#类的属性可以是其他类\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2= nn.Linear(in_features=120, out_features=60)\n",
    "        \n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "#out_features=10由数据决定，分成十类。\n",
    "\n",
    "#一般来说一个层的输出数目就是下一个层的输入数目。\n",
    "\n",
    "\n",
    "        \n",
    "#Network类包含属性：conv1，conv2，fc1，fc2和out一共5个属性，每个属性的值由nn\n",
    "#下面的一个类定义而成（类的属性可以是其他类），类位置在nn/modole/conv中并且加\n",
    "#入了适当的构造参数。其构造参数即为神经网络的“超参数”。超参数由设计者根据经验给出。\n",
    "#\n",
    "#Con2d为图片卷积层：包含三个参数：kernel_size，in_channels，out_features。\n",
    "#kernel_size：定义了卷积核的大小\n",
    "#in_channels：定义了输入的通道数\n",
    "#out_channels：定义了卷积核的数量，每个卷积核都能生成一个卷积图片（feature_maps）\n",
    "# out_features：全连阶层的输出，设计者决定。\n",
    "#一般来说附加的卷积层会提升输出的通道，线性层会一层一层收缩。\n",
    "#\n",
    "\n",
    "    def forward(self, t): \n",
    "        #(1) input layer\n",
    "        t=t\n",
    "        \n",
    "        #(2) hidden conv layer\n",
    "        t=self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        #relu和pooling不包含权重参数，只是操作，所以直接从torch.nn.functional引用\n",
    "        #大小为2的池化层会将每一个2x2的区域找出最大值并且返回，输出图片是之前的一半\n",
    "        \n",
    "        #(3) hidden conv layer\n",
    "        t=self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        #(4) hidden linear layer \n",
    "        t = t.reshape(-1,12*4*4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        #(5) hidden linear layer \n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        #(6) output layer\n",
    "        t = self.out(t)\n",
    "        #t = F.softmax(t, dim=1)\n",
    "        \n",
    "        #hidden layers多用ReLU激活函数，单一预测的输出层多用softmax激活函数\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_fast = nn.Sequential(\n",
    "        nn.Conv2d(1,6,5),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, stride=2),\n",
    "        nn.Conv2d(6,12,2),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2, stride=2),\n",
    "    #但是Reshape无法做？？\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "        root='./data/FashionMNIST',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([transforms.ToTensor()])\n",
    "        )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100)\n",
    "batch=next(iter(train_loader))\n",
    "images, labels = batch\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Network()\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3089704513549805"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = net(images)\n",
    "loss = F.cross_entropy(preds, labels)\n",
    "#loss函数会追踪计算图，用来做反向传播\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "print(preds.shape)\n",
    "print(labels.shape)\n",
    "#怎么比较的 交叉entropy，不同维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(net.conv1.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "retain_graph=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "#根据loss的计算图，将每个参数的梯度计算出来，位置对应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(net.conv1.weight.grad.shape)\n",
    "print(net.conv1.weight.shape)\n",
    "\n",
    "#梯度张量的形状和对应层权重一样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "#将神经网络的参数导入优化器，包括当前权重，当前梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3089704513549805"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_correct(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()\n",
    "#优化器的step方法，做一次优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = net(images)\n",
    "loss = F.cross_entropy(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.257197380065918"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_correct(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1401, 0.0936, 0.0893, 0.1422, 0.0614, 0.1250, 0.0734, 0.0702, 0.0576, 0.1473],\n",
       "        [0.1404, 0.0962, 0.0879, 0.1463, 0.0599, 0.1278, 0.0751, 0.0677, 0.0564, 0.1421],\n",
       "        [0.1254, 0.1013, 0.0952, 0.1249, 0.0764, 0.1160, 0.0918, 0.0766, 0.0764, 0.1159],\n",
       "        [0.1298, 0.1005, 0.0934, 0.1318, 0.0711, 0.1199, 0.0868, 0.0735, 0.0701, 0.1232],\n",
       "        [0.1407, 0.0968, 0.0847, 0.1508, 0.0599, 0.1274, 0.0742, 0.0671, 0.0562, 0.1421],\n",
       "        [0.1389, 0.0953, 0.0901, 0.1417, 0.0605, 0.1278, 0.0761, 0.0697, 0.0576, 0.1424],\n",
       "        [0.1308, 0.0959, 0.0946, 0.1318, 0.0665, 0.1243, 0.0832, 0.0761, 0.0650, 0.1318],\n",
       "        [0.1426, 0.0931, 0.0882, 0.1456, 0.0573, 0.1280, 0.0725, 0.0682, 0.0535, 0.1510],\n",
       "        [0.1257, 0.0993, 0.0970, 0.1244, 0.0749, 0.1190, 0.0897, 0.0776, 0.0754, 0.1169],\n",
       "        [0.1321, 0.0954, 0.0925, 0.1357, 0.0659, 0.1279, 0.0813, 0.0725, 0.0641, 0.1326],\n",
       "        [0.1355, 0.0985, 0.0906, 0.1395, 0.0653, 0.1238, 0.0806, 0.0698, 0.0628, 0.1334],\n",
       "        [0.1412, 0.0929, 0.0877, 0.1477, 0.0591, 0.1274, 0.0718, 0.0675, 0.0547, 0.1500],\n",
       "        [0.1285, 0.0977, 0.0942, 0.1305, 0.0685, 0.1257, 0.0851, 0.0756, 0.0676, 0.1267],\n",
       "        [0.1272, 0.0977, 0.0950, 0.1265, 0.0703, 0.1263, 0.0871, 0.0778, 0.0693, 0.1227],\n",
       "        [0.1255, 0.0981, 0.0960, 0.1258, 0.0712, 0.1241, 0.0874, 0.0783, 0.0715, 0.1222],\n",
       "        [0.1382, 0.0943, 0.0897, 0.1404, 0.0623, 0.1255, 0.0750, 0.0712, 0.0590, 0.1444],\n",
       "        [0.1348, 0.0981, 0.0900, 0.1398, 0.0639, 0.1269, 0.0797, 0.0709, 0.0616, 0.1343],\n",
       "        [0.1380, 0.0980, 0.0888, 0.1434, 0.0630, 0.1254, 0.0779, 0.0683, 0.0598, 0.1374],\n",
       "        [0.1360, 0.0967, 0.0923, 0.1356, 0.0650, 0.1227, 0.0807, 0.0720, 0.0625, 0.1365],\n",
       "        [0.1249, 0.1004, 0.0966, 0.1247, 0.0751, 0.1178, 0.0913, 0.0774, 0.0751, 0.1167],\n",
       "        [0.1397, 0.0973, 0.0869, 0.1482, 0.0617, 0.1258, 0.0761, 0.0671, 0.0579, 0.1393],\n",
       "        [0.1367, 0.0978, 0.0876, 0.1435, 0.0628, 0.1281, 0.0780, 0.0698, 0.0602, 0.1355],\n",
       "        [0.1371, 0.0970, 0.0899, 0.1401, 0.0645, 0.1233, 0.0785, 0.0708, 0.0616, 0.1375],\n",
       "        [0.1356, 0.0963, 0.0915, 0.1376, 0.0632, 0.1270, 0.0790, 0.0718, 0.0610, 0.1370],\n",
       "        [0.1400, 0.0952, 0.0893, 0.1439, 0.0605, 0.1256, 0.0758, 0.0686, 0.0569, 0.1442],\n",
       "        [0.1407, 0.0958, 0.0858, 0.1499, 0.0587, 0.1298, 0.0742, 0.0673, 0.0551, 0.1427],\n",
       "        [0.1361, 0.0967, 0.0911, 0.1394, 0.0620, 0.1287, 0.0779, 0.0710, 0.0604, 0.1368],\n",
       "        [0.1426, 0.0933, 0.0883, 0.1455, 0.0572, 0.1278, 0.0725, 0.0682, 0.0540, 0.1505],\n",
       "        [0.1322, 0.0985, 0.0927, 0.1345, 0.0681, 0.1222, 0.0838, 0.0731, 0.0659, 0.1290],\n",
       "        [0.1396, 0.0951, 0.0897, 0.1416, 0.0614, 0.1251, 0.0764, 0.0696, 0.0580, 0.1435],\n",
       "        [0.1227, 0.0987, 0.0961, 0.1233, 0.0734, 0.1233, 0.0895, 0.0800, 0.0754, 0.1177],\n",
       "        [0.1312, 0.1004, 0.0919, 0.1333, 0.0717, 0.1185, 0.0854, 0.0734, 0.0702, 0.1241],\n",
       "        [0.1375, 0.0958, 0.0905, 0.1398, 0.0620, 0.1266, 0.0780, 0.0710, 0.0595, 0.1391],\n",
       "        [0.1192, 0.1019, 0.0989, 0.1164, 0.0821, 0.1125, 0.0979, 0.0798, 0.0842, 0.1071],\n",
       "        [0.1227, 0.1011, 0.0970, 0.1215, 0.0777, 0.1173, 0.0938, 0.0780, 0.0791, 0.1119],\n",
       "        [0.1296, 0.0995, 0.0940, 0.1283, 0.0705, 0.1210, 0.0868, 0.0757, 0.0698, 0.1249],\n",
       "        [0.1295, 0.0982, 0.0952, 0.1284, 0.0726, 0.1183, 0.0861, 0.0747, 0.0718, 0.1252],\n",
       "        [0.1269, 0.0998, 0.0960, 0.1261, 0.0733, 0.1191, 0.0892, 0.0759, 0.0728, 0.1208],\n",
       "        [0.1393, 0.0963, 0.0847, 0.1492, 0.0590, 0.1339, 0.0735, 0.0676, 0.0559, 0.1406],\n",
       "        [0.1428, 0.0937, 0.0880, 0.1469, 0.0580, 0.1261, 0.0728, 0.0668, 0.0541, 0.1508],\n",
       "        [0.1382, 0.0957, 0.0908, 0.1401, 0.0619, 0.1247, 0.0774, 0.0702, 0.0592, 0.1417],\n",
       "        [0.1302, 0.0960, 0.0942, 0.1309, 0.0673, 0.1256, 0.0832, 0.0757, 0.0653, 0.1317],\n",
       "        [0.1393, 0.0933, 0.0890, 0.1419, 0.0609, 0.1264, 0.0738, 0.0711, 0.0567, 0.1477],\n",
       "        [0.1299, 0.0967, 0.0931, 0.1305, 0.0679, 0.1276, 0.0842, 0.0766, 0.0657, 0.1279],\n",
       "        [0.1418, 0.0924, 0.0876, 0.1481, 0.0564, 0.1313, 0.0710, 0.0672, 0.0533, 0.1509],\n",
       "        [0.1335, 0.0976, 0.0932, 0.1337, 0.0671, 0.1219, 0.0828, 0.0729, 0.0649, 0.1323],\n",
       "        [0.1307, 0.0957, 0.0944, 0.1303, 0.0672, 0.1246, 0.0835, 0.0775, 0.0656, 0.1304],\n",
       "        [0.1401, 0.0973, 0.0861, 0.1487, 0.0603, 0.1281, 0.0757, 0.0670, 0.0564, 0.1402],\n",
       "        [0.1345, 0.0983, 0.0912, 0.1386, 0.0646, 0.1265, 0.0807, 0.0704, 0.0626, 0.1325],\n",
       "        [0.1421, 0.0946, 0.0863, 0.1506, 0.0578, 0.1286, 0.0727, 0.0671, 0.0539, 0.1464],\n",
       "        [0.1394, 0.0974, 0.0857, 0.1489, 0.0622, 0.1264, 0.0760, 0.0673, 0.0582, 0.1384],\n",
       "        [0.1375, 0.0978, 0.0882, 0.1450, 0.0637, 0.1244, 0.0780, 0.0689, 0.0605, 0.1360],\n",
       "        [0.1314, 0.0967, 0.0936, 0.1329, 0.0665, 0.1246, 0.0827, 0.0757, 0.0647, 0.1312],\n",
       "        [0.1444, 0.0929, 0.0874, 0.1478, 0.0568, 0.1266, 0.0716, 0.0667, 0.0529, 0.1528],\n",
       "        [0.1252, 0.1004, 0.0963, 0.1241, 0.0750, 0.1179, 0.0913, 0.0772, 0.0753, 0.1172],\n",
       "        [0.1378, 0.0971, 0.0901, 0.1414, 0.0636, 0.1237, 0.0781, 0.0688, 0.0605, 0.1388],\n",
       "        [0.1369, 0.0964, 0.0886, 0.1442, 0.0611, 0.1306, 0.0772, 0.0692, 0.0579, 0.1381],\n",
       "        [0.1356, 0.0977, 0.0902, 0.1387, 0.0647, 0.1253, 0.0795, 0.0717, 0.0623, 0.1342],\n",
       "        [0.1407, 0.0970, 0.0853, 0.1499, 0.0618, 0.1247, 0.0747, 0.0671, 0.0575, 0.1414],\n",
       "        [0.1354, 0.0980, 0.0882, 0.1427, 0.0654, 0.1265, 0.0791, 0.0705, 0.0624, 0.1319],\n",
       "        [0.1342, 0.0949, 0.0922, 0.1374, 0.0650, 0.1258, 0.0792, 0.0724, 0.0621, 0.1368],\n",
       "        [0.1336, 0.0976, 0.0921, 0.1369, 0.0653, 0.1258, 0.0817, 0.0719, 0.0632, 0.1318],\n",
       "        [0.1260, 0.0983, 0.0959, 0.1256, 0.0718, 0.1255, 0.0886, 0.0774, 0.0712, 0.1197],\n",
       "        [0.1215, 0.1004, 0.0984, 0.1215, 0.0767, 0.1194, 0.0933, 0.0781, 0.0789, 0.1118],\n",
       "        [0.1396, 0.0968, 0.0872, 0.1474, 0.0606, 0.1281, 0.0754, 0.0670, 0.0572, 0.1406],\n",
       "        [0.1358, 0.0969, 0.0920, 0.1366, 0.0647, 0.1230, 0.0805, 0.0713, 0.0622, 0.1369],\n",
       "        [0.1384, 0.0973, 0.0892, 0.1436, 0.0625, 0.1251, 0.0774, 0.0678, 0.0593, 0.1394],\n",
       "        [0.1389, 0.0968, 0.0874, 0.1456, 0.0613, 0.1287, 0.0757, 0.0685, 0.0583, 0.1388],\n",
       "        [0.1345, 0.0972, 0.0924, 0.1352, 0.0659, 0.1231, 0.0813, 0.0730, 0.0638, 0.1335],\n",
       "        [0.1345, 0.0979, 0.0881, 0.1414, 0.0647, 0.1290, 0.0791, 0.0710, 0.0627, 0.1315],\n",
       "        [0.1423, 0.0940, 0.0860, 0.1508, 0.0577, 0.1294, 0.0715, 0.0659, 0.0534, 0.1491],\n",
       "        [0.1356, 0.0977, 0.0880, 0.1429, 0.0629, 0.1302, 0.0781, 0.0699, 0.0607, 0.1339],\n",
       "        [0.1316, 0.0993, 0.0928, 0.1336, 0.0684, 0.1241, 0.0843, 0.0731, 0.0670, 0.1258],\n",
       "        [0.1418, 0.0965, 0.0842, 0.1519, 0.0600, 0.1270, 0.0734, 0.0665, 0.0559, 0.1429],\n",
       "        [0.1361, 0.0969, 0.0871, 0.1445, 0.0616, 0.1328, 0.0767, 0.0694, 0.0593, 0.1355],\n",
       "        [0.1425, 0.0948, 0.0870, 0.1491, 0.0587, 0.1261, 0.0731, 0.0664, 0.0544, 0.1478],\n",
       "        [0.1391, 0.0966, 0.0875, 0.1467, 0.0604, 0.1288, 0.0756, 0.0685, 0.0571, 0.1396],\n",
       "        [0.1342, 0.0978, 0.0926, 0.1360, 0.0655, 0.1233, 0.0810, 0.0720, 0.0635, 0.1341],\n",
       "        [0.1326, 0.0991, 0.0897, 0.1380, 0.0669, 0.1267, 0.0819, 0.0721, 0.0650, 0.1281],\n",
       "        [0.1394, 0.0934, 0.0881, 0.1472, 0.0577, 0.1329, 0.0722, 0.0682, 0.0547, 0.1463],\n",
       "        [0.1386, 0.0964, 0.0858, 0.1474, 0.0595, 0.1333, 0.0750, 0.0680, 0.0569, 0.1393],\n",
       "        [0.1278, 0.1010, 0.0935, 0.1296, 0.0739, 0.1187, 0.0888, 0.0748, 0.0731, 0.1188],\n",
       "        [0.1286, 0.0978, 0.0945, 0.1297, 0.0702, 0.1246, 0.0857, 0.0759, 0.0695, 0.1234],\n",
       "        [0.1325, 0.0960, 0.0935, 0.1325, 0.0657, 0.1252, 0.0817, 0.0755, 0.0636, 0.1338],\n",
       "        [0.1391, 0.0943, 0.0896, 0.1435, 0.0630, 0.1230, 0.0745, 0.0684, 0.0586, 0.1460],\n",
       "        [0.1292, 0.0978, 0.0948, 0.1289, 0.0702, 0.1222, 0.0854, 0.0763, 0.0683, 0.1270],\n",
       "        [0.1381, 0.0966, 0.0860, 0.1474, 0.0599, 0.1333, 0.0753, 0.0680, 0.0573, 0.1381],\n",
       "        [0.1269, 0.0977, 0.0961, 0.1268, 0.0704, 0.1221, 0.0871, 0.0782, 0.0701, 0.1245],\n",
       "        [0.1393, 0.0944, 0.0895, 0.1445, 0.0621, 0.1237, 0.0742, 0.0687, 0.0582, 0.1452],\n",
       "        [0.1337, 0.0957, 0.0921, 0.1345, 0.0662, 0.1241, 0.0799, 0.0740, 0.0629, 0.1368],\n",
       "        [0.1298, 0.0979, 0.0945, 0.1278, 0.0722, 0.1197, 0.0853, 0.0758, 0.0704, 0.1267],\n",
       "        [0.1354, 0.0980, 0.0895, 0.1397, 0.0666, 0.1228, 0.0796, 0.0714, 0.0641, 0.1329],\n",
       "        [0.1256, 0.1000, 0.0959, 0.1261, 0.0732, 0.1214, 0.0898, 0.0759, 0.0737, 0.1185],\n",
       "        [0.1368, 0.0948, 0.0908, 0.1381, 0.0636, 0.1245, 0.0767, 0.0722, 0.0604, 0.1420],\n",
       "        [0.1378, 0.0975, 0.0886, 0.1441, 0.0629, 0.1257, 0.0779, 0.0689, 0.0597, 0.1368],\n",
       "        [0.1315, 0.0983, 0.0939, 0.1306, 0.0690, 0.1213, 0.0850, 0.0746, 0.0672, 0.1287],\n",
       "        [0.1231, 0.1011, 0.0972, 0.1218, 0.0777, 0.1161, 0.0937, 0.0781, 0.0785, 0.1126],\n",
       "        [0.1389, 0.0958, 0.0856, 0.1491, 0.0591, 0.1338, 0.0730, 0.0682, 0.0559, 0.1405],\n",
       "        [0.1358, 0.0975, 0.0893, 0.1413, 0.0629, 0.1286, 0.0789, 0.0706, 0.0609, 0.1342],\n",
       "        [0.1362, 0.0964, 0.0907, 0.1355, 0.0642, 0.1258, 0.0790, 0.0731, 0.0616, 0.1376]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(preds, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
